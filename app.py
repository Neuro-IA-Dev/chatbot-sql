import os
import json
import numpy as np
import datetime
import requests
import streamlit as st
import mysql.connector
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from openai import OpenAI
from pathlib import Path
import csv

# CONFIGURACIÃ“N INICIAL
st.set_page_config(page_title="Asistente Inteligente de NeuroVIA", page_icon="ğŸ§ ")
st.image("assets/logo_neurovia.png", width=180)
st.title("ğŸ§  Asistente Inteligente de Intanis/NeuroVIA")

if st.button("ğŸ§¹ Borrar historial de preguntas", key="btn_borrar_historial"):
    st.session_state["historial"] = []
    st.session_state["conversacion"] = []
    st.success("Historial de conversaciÃ³n borrado.")

st.markdown("Haz una pregunta y el sistema generarÃ¡ y ejecutarÃ¡ una consulta SQL automÃ¡ticamente.")

# Inicializar historial en la sesiÃ³n
if "historial" not in st.session_state:
    st.session_state["historial"] = []

if "conversacion" not in st.session_state:
    st.session_state["conversacion"] = []

# Mostrar historial conversacional
for entrada in st.session_state["conversacion"]:
    st.markdown(f"**ğŸ§  Pregunta:** {entrada['pregunta']}")
    st.markdown(f"**ğŸ’¬ Respuesta:** {entrada['respuesta']}")
    st.markdown("---")

# API OPENAI
llm = ChatOpenAI(temperature=0)

# CONEXIÃ“N A MySQL
def connect_db():
    return mysql.connector.connect(
        host="s1355.use1.mysecurecloudhost.com",
        port=3306,
        user="domolabs_RedTabBot_USER",
        password="Pa$$w0rd_123",
        database="domolabs_RedTabBot_DB"
    )

# VALIDACIÃ“N DE CONSULTAS SQL
def es_consulta_segura(sql):
    sql = sql.lower()
    comandos_peligrosos = ["drop", "delete", "truncate", "alter", "update", "insert", "--", "/*", "grant", "revoke"]
    return not any(comando in sql for comando in comandos_peligrosos)

# ESQUEMA DE LA BASE DE DATOS PARA EL PROMPT
db_schema = """
Base de datos: domolabs_RedTabBot_DB
Tabla: VENTAS (con columnas como COD_TIENDA, DESC_TIENDA, COD_CANAL, DESC_CANAL, INGRESOS, COSTOS, UNIDADES, MONEDA, etc.)
"""

sql_prompt = PromptTemplate(
    input_variables=["pregunta"],
    template=f"""
Eres un asistente experto en anÃ¡lisis de datos para una empresa de retail. Tu tarea es interpretar preguntas en lenguaje natural y generar la consulta SQL correcta para obtener la informaciÃ³n desde una Ãºnica tabla llamada `VENTAS`.

La tabla `VENTAS` contiene informaciÃ³n histÃ³rica de ventas, productos, tiendas, marcas, canales, clientes y artÃ­culos. Todos los datos estÃ¡n contenidos en esa misma tabla, por lo que no necesitas hacer JOINs.

ğŸ” Usa las siguientes reglas de mapeo inteligente:

1. Si el usuario menciona tÃ©rminos como "tienda", "cliente", "marca", "canal", "producto", "temporada", etc., asume que se refiere a su campo descriptivo (`DESC_...`) y **no al cÃ³digo (`COD_...`)**, excepto que el usuario especifique explÃ­citamente â€œcÃ³digo de...â€.
   - Ejemplo: "tienda" â†’ `DESC_TIENDA`
   - Ejemplo: "cÃ³digo de tienda" â†’ `COD_TIENDA`

2. Si el usuario pide:
   - "Â¿CuÃ¡ntas tiendas?" o "total de tiendas": usa `COUNT(DISTINCT DESC_TIENDA)`
   - "Â¿CuÃ¡ntos canales?" â†’ `COUNT(DISTINCT DESC_CANAL)`
   - "Â¿CuÃ¡ntos clientes?" â†’ `COUNT(DISTINCT NOMBRE_CLIENTE)`
   - Aplica la lÃ³gica `COUNT(DISTINCT ...)` para cualquier atributo que tenga mÃºltiples registros.

3. Siempre que se mencione:
   - "ventas", "ingresos": usar la columna `INGRESOS`
   - "costos": usar `COSTOS`
   - "unidades vendidas": usar `UNIDADES`
   - "producto", "artÃ­culo", "sku": puedes usar `DESC_ARTICULO` o `DESC_SKU` dependiendo del contexto.

4. No asumas que hay relaciones externas: toda la informaciÃ³n estÃ¡ embebida en el tablon `VENTAS`.

5. Cuando pregunten por montos como ingresos o ventas, consulta si la informaciÃ³n requerida debe ser en CLP o USD. Esta informaciÃ³n estÃ¡ disponible en la columna `MONEDA`.

6. Cuando pregunten algo como "muestrame el codigo y descripcion de todas las tiendas que hay" debes hacer un distinct.

ğŸ” Recuerda usar `WHERE`, `GROUP BY` o `ORDER BY` cuando el usuario pregunte por filtros, agrupaciones o rankings.

âœï¸ Cuando generes la consulta SQL, no expliques la respuesta â€”solo entrega el SQL limpio y optimizado para MySQL.

Este es el esquema de la base de datos:
{db_schema}

Ahora responde esta nueva pregunta:
Pregunta: {{pregunta}}

SQL:
"""
)

# LOG DE INTERACCIONES EN BASE DE DATOS
def log_interaction(pregunta, sql, resultado):
    try:
        conn = connect_db()
        cursor = conn.cursor()
        insert_query = """
            INSERT INTO chat_logs (pregunta, sql_generado, resultado)
            VALUES (%s, %s, %s)
        """
        cursor.execute(insert_query, (pregunta, sql, resultado))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        st.warning(f"âš ï¸ No se pudo guardar el log en la base de datos: {e}")
# SEMANTIC CACHE

from openai import OpenAI
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

def obtener_embedding(texto):
    if not texto or not texto.strip():
        st.warning("âŒ El texto para obtener embedding estÃ¡ vacÃ­o.")
        return None

    try:
        response = client.embeddings.create(
            input=[texto],
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    except Exception as e:
        st.warning(f"Error al obtener embedding: {e}")
        return None

def guardar_en_cache(pregunta, sql_generado, embedding):
    try:
        conn = connect_db()
        cursor = conn.cursor()
        query = "INSERT INTO semantic_cache (pregunta, embedding, sql_generado) VALUES (%s, %s, %s)"
        cursor.execute(query, (pregunta, json.dumps(embedding), sql_generado))
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as e:
        st.warning(f"No se pudo guardar en el semantic cache: {e}")

def buscar_sql_en_cache(pregunta_nueva, umbral_similitud=0.90):
    try:
        embedding_nuevo = obtener_embedding(pregunta_nueva)
        if embedding_nuevo is None:
            return None

        embedding_nuevo = np.array(embedding_nuevo)

        conn = connect_db()
        cursor = conn.cursor(dictionary=True)
        cursor.execute("SELECT pregunta, embedding, sql_generado FROM semantic_cache")
        rows = cursor.fetchall()
        cursor.close()
        conn.close()

        for row in rows:
            try:
                embedding_guardado = json.loads(row["embedding"])
                if embedding_guardado is None:
                    continue

                embedding_guardado = np.array(embedding_guardado)
                similitud = np.dot(embedding_nuevo, embedding_guardado) / (
                    np.linalg.norm(embedding_nuevo) * np.linalg.norm(embedding_guardado)
                )

                if similitud >= umbral_similitud:
                    return row["sql_generado"]
            except Exception as e:
                st.warning(f"Error comparando embeddings: {e}")

        return None
    except Exception as e:
        st.warning(f"Error al buscar en el semantic cache: {e}")
        return None
    except Exception as e:
        st.warning(f"Error al buscar en el semantic cache: {e}")
        return None
# ENTRADA
pregunta = st.chat_input("ğŸ§  Pregunta en lenguaje natural")

if pregunta:
    st.markdown(f"**ğŸ“ Pregunta:** {pregunta}")

    contexto = ""
    for i, (preg, sql) in enumerate(st.session_state["historial"][-5:]):
        contexto += f"Pregunta anterior: {preg}\nSQL generado: {sql}\n"

if pregunta:
    st.markdown(f"**ğŸ“ Pregunta:** {pregunta}")

    sql_query = buscar_sql_en_cache(pregunta)

    if sql_query:
        st.info("ğŸ” Se reutilizÃ³ una consulta SQL previamente generada por similitud semÃ¡ntica.")
    else:
        prompt = sql_prompt.format_prompt(pregunta=pregunta).to_string()
        sql_query = llm.predict(prompt).strip().strip("```sql").strip("```")

        embedding = obtener_embedding(pregunta)
        if embedding:
            guardar_en_cache(pregunta, sql_query, embedding)

    st.session_state["historial"].append((pregunta, sql_query))

    st.markdown("ğŸ” **Consulta SQL Generada:**")
    st.code(sql_query, language="sql")

    try:
        if not es_consulta_segura(sql_query):
            st.error("âŒ La consulta generada contiene comandos peligrosos y no serÃ¡ ejecutada.")
            log_interaction(pregunta, sql_query, "Consulta bloqueada por seguridad")
        else:
            conn = connect_db()
            cursor = conn.cursor()
            cursor.execute(sql_query)

            if sql_query.lower().startswith("select"):
                columns = [col[0] for col in cursor.description]
                results = cursor.fetchall()
                df = pd.DataFrame(results, columns=columns)
                st.dataframe(df)
                resultado_str = f"{len(df)} filas"
            else:
                conn.commit()
                resultado_str = "Consulta ejecutada correctamente."

            cursor.close()
            conn.close()

            st.markdown(f"**ğŸ’¬ Respuesta:** {resultado_str}")
            log_interaction(pregunta, sql_query, resultado_str)
            st.session_state["conversacion"].append({"pregunta": pregunta, "respuesta": resultado_str})

    except Exception as e:
        st.error(f"âŒ Error al ejecutar la consulta: {e}")
        log_interaction(pregunta, sql_query, f"Error: {e}")
        st.session_state["conversacion"].append({"pregunta": pregunta, "respuesta": str(e)})

# ğŸ”„ VER HISTORIAL DE PREGUNTAS
st.markdown("---")
st.subheader("ğŸ“š Historial de consultas anteriores")

if st.toggle("ğŸ“‹ Mostrar historial de preguntas", key="toggle_historial"):
    try:
        conn = connect_db()
        df_logs = pd.read_sql("SELECT id, fecha, pregunta, sql_generado, resultado FROM chat_logs ORDER BY fecha DESC", conn)
        conn.close()

        st.dataframe(df_logs, use_container_width=True)

        csv_logs = df_logs.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ Descargar historial como CSV",
            data=csv_logs,
            file_name="historial_chat_logs.csv",
            mime="text/csv"
        )
    except Exception as e:
        st.error(f"âŒ Error al cargar logs desde la base de datos: {e}")

# DASHBOARD
st.markdown("---")
st.subheader("ğŸ“ˆ EstadÃ­sticas de uso del asistente")

if st.toggle("ğŸ“Š Mostrar dashboard de uso", key="toggle_dashboard"):
    try:
        conn = connect_db()
        df_stats = pd.read_sql("SELECT * FROM chat_logs", conn)
        conn.close()

        total_preguntas = len(df_stats)
        errores = df_stats["resultado"].str.contains("error", case=False, na=False).sum()
        ultima_fecha = df_stats["fecha"].max()
        tipos = df_stats["sql_generado"].str.extract(r'^\s*(\w+)', expand=False).value_counts()

        col1, col2, col3 = st.columns(3)
        col1.metric("Total de preguntas", total_preguntas)
        col2.metric("Errores detectados", errores)
        col3.metric("Ãšltimo uso", ultima_fecha.strftime("%Y-%m-%d %H:%M:%S") if pd.notna(ultima_fecha) else "N/A")

        st.markdown("#### ğŸ” DistribuciÃ³n por tipo de consulta SQL")
        st.bar_chart(tipos)

    except Exception as e:
        st.error(f"âŒ No se pudieron cargar las mÃ©tricas: {e}")

# MONITOREO DE COSTOS OPENAI
def obtener_consumo_openai(api_key):
    try:
        hoy = datetime.date.today()
        inicio_mes = hoy.replace(day=1)
        url = f"https://api.openai.com/v1/dashboard/billing/usage?start_date={inicio_mes}&end_date={hoy}"

        headers = {
            "Authorization": f"Bearer {api_key}"
        }

        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            data = response.json()
            usd = data.get("total_usage", 0) / 100
            return round(usd, 2)
        elif response.status_code == 401:
            return "âŒ Error 401: API Key invÃ¡lida o sin permisos de uso"
        else:
            return f"âŒ Error {response.status_code}: {response.text}"

    except Exception as e:
        return f"âŒ ExcepciÃ³n: {e}"

if st.toggle("ğŸ’° Ver costo acumulado en OpenAI", key="toggle_costos_openai"):
    with st.spinner("Consultando consumo..."):
        consumo = obtener_consumo_openai(st.secrets["OPENAI_API_KEY"])
        st.metric("Consumo actual OpenAI (mes)", f"${consumo}")



# Revisar IP
import requests

try:
    ip = requests.get("https://api64.ipify.org").text
    st.markdown(f"ğŸŒ **IP pÃºblica del servidor (Streamlit):** `{ip}`")
except Exception as e:
    st.warning(f"No se pudo obtener la IP pÃºblica: {e}")
